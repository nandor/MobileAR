// This file is part of the MobileAR Project.
// Licensing information can be found in the LICENSE file.
// (C) 2015 Nandor Licker. All rights reserved.

#import <AVFoundation/AVFoundation.h>
#import <CoreLocation/CoreLocation.h>

#import "ARCalibrator.h"
#import "UIImage+cvMat.h"
#import "MobileAR-Swift.h"

#include <opencv2/opencv.hpp>


/// Number of snapshots taken for calibration.
static constexpr size_t kCalibrationPoints = 64;
/// Minimal average distance between points in two sets.
static constexpr double kMinDistance = 5.0f;
/// Size of the asymetric circle pattern.
static const cv::Size kPatternSize(4, 11);


/**
 Computes the distance between two sets of image points.
 */
static double distance(
    const std::vector<cv::Point2f> &xs,
    const std::vector<cv::Point2f>& ys)
{
  assert(xs.size() == ys.size());
  
  float sum = 0.0f;
  for (size_t i = 0; i < xs.size(); ++i) {
    const auto dist = xs[i] - ys[i];
    sum += std::sqrt(dist.dot(dist));
  }
  return std::sqrt(sum / xs.size());
}


/**
 Computes the minimal distance between a point and any sets of points.
 */
static double distance(
    const std::vector<std::vector<cv::Point2f>> &xxs,
    const std::vector<cv::Point2f> &ys)
{
  auto min = std::numeric_limits<double>::max();
  for (const auto &xs: xxs) {
    min = std::min(min, distance(xs, ys));
  }
  return min;
}



@implementation ARCalibrator
{
  // OpenCV images.
  cv::Mat gray;
  cv::Mat bgra;
  cv::Mat rgba;

  // Buffer for calibration points.
  std::vector<std::vector<cv::Point2f>> imagePoints;
  std::vector<cv::Point3f> grid;

  // Computed parameters.
  cv::Mat cameraMatrix;
  cv::Mat distCoeffs;

  // Delegate that handles events.
  id<ARCalibratorDelegate> delegate;
  
  // Focal distance.
  NSNumber *focus;
}

- (instancetype)initWithDelegate:(id)delegate_
{
  if (!(self = [super init])) {
    return nil;
  }

  delegate = delegate_;

  // Initialize the intrinsic parameters.
  cameraMatrix = cv::Mat::eye(3, 3, CV_64F);
  distCoeffs = cv::Mat::zeros(4, 1, CV_64F);

  // Reserve storage for the point sets.
  imagePoints.reserve(kCalibrationPoints);

  // Initialize the coordinates in the grid pattern.
  for (int i = 0; i < kPatternSize.height; i++ ) {
    for (int j = 0; j < kPatternSize.width; j++) {
      grid.emplace_back((2 * j + i % 2) * 4.0f, i * 4.0f, 0.0f);
    }
  }

  // No focal point set.
  focus = nil;
  
  return self;
}

- (UIImage*)findPattern:(UIImage*)frame
{
  // Focal distance must be set for calibration.
  if (focus == nil) {
    return frame;
  }
  
  // Convert rgb to bgra.
  [frame toCvMat:bgra];
  cv::cvtColor(bgra, rgba, CV_BGRA2RGBA);
  cv::cvtColor(rgba, gray, CV_RGBA2GRAY);

  // Find the chessboard.
  std::vector<cv::Point2f> corners;
  auto found = cv::findCirclesGrid(
      gray,
      kPatternSize,
      corners,
      cv::CALIB_CB_ASYMMETRIC_GRID | cv::CALIB_CB_CLUSTERING
  );
  if (!found) {
    return frame;
  }

  // Draw the detected pattern.
  cv::drawChessboardCorners(rgba, kPatternSize, cv::Mat(corners), found);
  
  // If enough points were captured, bail out.
  if (imagePoints.size() >= kCalibrationPoints) {
    return [UIImage imageWithCvMat: rgba];
  }
  
  // If distance between two sets too small, return.
  if (distance(imagePoints, corners) < kMinDistance) {
    return [UIImage imageWithCvMat: rgba];
  }

  // Add the point to the set of calibration points and report progress.
  imagePoints.push_back(corners);
  if ([delegate respondsToSelector: @selector(onProgress:)]) {
    [delegate onProgress:static_cast<float>(imagePoints.size()) / kCalibrationPoints];
  }

  // If enough points were recorded, start calibrating in a backgroud thread.
  if (imagePoints.size() == kCalibrationPoints) {
    // Otherwise, calibrate in a background thread.
    dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{
      auto rms = static_cast<float>(cv::calibrateCamera(
          std::vector<std::vector<cv::Point3f>>(kCalibrationPoints, grid),
          imagePoints,
          rgba.size(),
          cameraMatrix,
          distCoeffs,
          {},
          {},
          0
      ));
      cameraMatrix.convertTo(cameraMatrix, CV_32F);
      distCoeffs.convertTo(distCoeffs, CV_32F);

      if ([delegate respondsToSelector:@selector(onComplete:params:)]) {
        [delegate onComplete:rms params:[[ARParameters alloc]
            initWithFx: cameraMatrix.at<float>(0, 0)
                    fy: cameraMatrix.at<float>(1, 1)
                    cx: cameraMatrix.at<float>(0, 2)
                    cy: cameraMatrix.at<float>(1, 2)
                    k1: distCoeffs.at<float>(0, 0)
                    k2: distCoeffs.at<float>(1, 0)
                    r1: distCoeffs.at<float>(2, 0)
                    r2: distCoeffs.at<float>(3, 0)
                     f: [focus floatValue]
        ]];
      }
    });
  }

  return [UIImage imageWithCvMat: rgba];
}


- (void)focus:(float)f x:(float)x y:(float)y
{
  focus = @(f);
  
  imagePoints.clear();
  
  if ([delegate respondsToSelector:@selector(onProgress:)]) {
    [delegate onProgress: 0.0f];
  }
}

@end